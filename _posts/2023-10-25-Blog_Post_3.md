# Personal Experience with Model Selection

In my experience as a Neuroscience researcher, which includes publications in tier-one journals, the selection of models to use in one's analysis of data can often be a controversy.  In the best cases, the researcher would have formed a solid hypothesis about what they expect to happen due to their independent variable intervention, such as when they have targetted a gene to modify and that the result would be a situation where the animal behaves in modalities reminescent of the illness that they are attempting to model.  In which case, they would predict things like this animal will fall more quickly off of a rota-rod task or that it would take more time to come into the light section of a light-dark maze.  With these hypotheses, complex models are not necessary.  

# [Dilemma](https://www.youtube.com/watch?v=8WYHDfJDPDc)

However, when the animal does not behave the way that they predict, or no results are obvious in the data, it is not uncommon for researchers to want to dig deeper into their data.  This is understandable, as oftentimes much time, money, and effort has been expended in creating these animal models.  Often, this is not done in an unbiased manner (which may draw some ethical questions).  The researchers may look at the raw data and attempt to draw associations between variables which were not part of their original hypotheses and, subsequently, may want to include these new associations in analysis or, in the more ethical approach, decide to repeat their experiment, modifying their hypotheses and trying to figure out why these previously unexpected results may have occurred with further literature review (to be addressed in their introductions or a literature review section).  Unfortunately, results which are not what the research has predicted often go unpublished, leaving the rest of the scientific community unawares of these potentially useful, if not statistically significant in the manner originally desired.  

# Model Selection

Another approach that researchers may take to pull apart their data is utilizing model selection techniques, such as forward, backward, step-wise, or other approaches.  Each of these approaches have their own benefits and drawbacks.  And, as referenced in the Ratner article, often what happens is that researchers simply choose the model that they are personally most used to and feel comfortable with.  Ratner brings up the important point that it would benefit researchers to instead utilize the 7-step method described by Tukey to choose a model based on logic rather than personal comfort.  These steps are:

1. Definition of the problem. 
2. Determining technique. 
3. Use of competing techniques. 
4. Rough comparisons of efficacy. 
5. Comparison in terms of a precise (and thereby inadequate) criterion.
6. Optimization in terms of a precise and similarly inadequate criterion.
7. Comparison in terms of several optimization criteria. 

Utilizing these techniques allows researchers to follow a system that allows for optimal model selection.  This would best performed when researchers have formed ideas of which variables would have the most use for their research and then selecting these variables to be put through a selection process.  If they have a hierarchy of which variables they think are most useful, it may be best to go through a forward or step-wise selection process.  If they think that all of the variables are equally useful, and want the model to provide some insight into which variables should be excluded from analysis, a backward seleciton process may be better, as it would remove the lease useful variables one-by-one.  It is often not useful to include all possible variables in models, as this may result in over-parameterization and then all models would likely provide very similar results... as I saw on the most recent homework when trying out what would happen if including all possible variables in both forward and backward selection are received the same exact results as determined by RMSE.

# References:
Ratner, B. (n.d.). Variable selection methods in regression: Ignorable problem ... - springer. https://link.springer.com/content/pdf/10.1057/jt.2009.26.pdf 
Heinze, G., Wallisch, C., & Dunkler, D. (2018). Variable selection - A review and recommendations for the practicing statistician. Biometrical Journal, 60(3), 431â€“449. https://doi.org/10.1002/bimj.201700067
Variable Selection. (n.d.). https://www.biostat.jhsph.edu/~iruczins/teaching/jf/ch10.pdf
